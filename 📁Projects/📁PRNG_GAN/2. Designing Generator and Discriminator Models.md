GAN have two key components Generator (G) and Discriminator (D)
1. Define the architecture for **G** and **D**
2. Implement them using Python and TensorFlow/Keras

---
## 2.1 Generator (G)
The generator creates pseudo-random sequences

1. **Design:**
	- Input: A vector of size 2:
		- A random seed $(s)$
		- A non-random scalar offset $(o)$
	- Output: A sequence of size 8

2. **Architecture:**
	- Fully Connected Feed-Forward (FCFF) network
	- Four hidden layers with **30 units each** and **leaky ReLU activation**
	- Final layer with a custom `mod` activation to constrain the output to a specific range.

Generator Implementation #function 
```python
import tensorflow as tf

def build_generator(input_dim):
	"""
	Builds the generator model
	Args:
		input_dim (int): Dimension of the input vector [seed + offset]
	Returns:
		tf.keras.Model: Generator model
	"""
	model = tf.keras.Sequential([
		tf.keras.layers.InputLayer(input_dim),  # Input Layer
		tf.keras.layers.Dense(30, activation=tf.keras.layers.LeakyReLU(0.2)),
		tf.keras.layers.Dense(30, activation=tf.keras.layers.LeakyReLU(0.2)),
		tf.keras.layers.Dense(30, activation=tf.keras.layers.LeakyReLU(0.2)),
		tf.keras.layers.Dense(8, activation=lambda x: tf.math.mod(x, 1.0))  # Constain outputs
	])
	return model
```

```python
# build and summarizer the generator 
generator = build_generator(input_dim=2) # seed + offset
generator.summary()
```

---
## 2.2 Discriminator (D)
The discriminator distinguish between:
- Real random sequences 
- Fake sequences generated by G

1. **Design:**
- Input: A sequence of 8 numbers
- Output: A probability score (real or fake)

2. **Architecture:**
- Four convolutional layers with **4 filters each**, kernel size 2, stride 1 and ReLU activation.
- MaxPooling after each convolutional layer.
- Two dense (fully connected) layers for final classification

Discriminator Implementation #function 
```python
def build_discriminator(input_dim):
	"""
	Builds the discriminator model.
	Args:
		input_dim (int): Dimension of the input sequence
	Returns:
		tf.keras.Model: Discrtiminator model
	"""
	model = tf.keras.Sequential([
		tf.keras.layers.InputLayer((input_dim, 1)),  # Input Layer (reshape for convolution)
		tf.keras.layers.Conv1D(4, kernel_size=2, strides=1, activation='relu'),
		tf.keras.layers.MaxPooling1D(pool_size=2),
		tf.keras.layers.Conv1D(4, kernel_size=2, strides=1, activation='relu'),
		tf.keras.layers.MaxPooling1D(pool_size=2),
		tf.keras.layers.Flatten(),  # Flatten before dense layers
		tf.keras.layers.Dense(4, activation='relu'),
		tf.keras.layers.Dense(1, activation='sigmoid')  # Output: Real (1) or Fake (0)
	])
	return model
```

```python
# Build and summarize the discriminator
discriminator = build_discriminator(input_dim=8)  # Input is a sequence of 8 numbers
discriminator.summary()
```

---
## 2.3 Testing Models
After defining G and D, testing their functionality to ensure they behave as expected

Testing Generator and Discriminator  #function 
```python
# Generate a random input for the generator 
seed = tf.random.uniform((1, 1))  # Random seed
offset = tf.constant([[0.5]])  # Example offset
gen_input = tf.concat([seed, offset], axis=1)  # Combine seed and offset

# Generate fake data
fake_data = generator(gen_input)
print(f'Generated fake data: {fake_data.numpy()}')

# Test discriminator with real and fake data 
real_data = tf.random.uniform((1, 8), 0, 1) # Real random data 
real_score = discriminator(tf.expand_dims(real_data, -1)) # Add channel for Conv1D 
fake_score = discriminator(tf.expand_dims(fake_data, -1)) print("Discriminator score for real data:", real_score.numpy()) print("Discriminator score for fake data:", fake_score.numpy())
```
